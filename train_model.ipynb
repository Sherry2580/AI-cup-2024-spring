{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Train Pix2Pix model for image-to-image translation\n","\n","make sure you have done the dataset preparation before running this notebook. "]},{"cell_type":"markdown","metadata":{"id":"7wNjDKdQy35h"},"source":["# Install"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1204,"status":"ok","timestamp":1710751107262,"user":{"displayName":"D Parejo","userId":"17109521203490422964"},"user_tz":-480},"id":"TRm-USlsHgEV","outputId":"93cc884a-52d9-4541-f9b5-8efe6096f00b"},"outputs":[],"source":["import os\n","\n","# check if `pytorch-CycleGAN-and-pix2pix` is already cloned\n","if not os.path.exists('pytorch-CycleGAN-and-pix2pix'):\n","\t!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1710751107262,"user":{"displayName":"D Parejo","userId":"17109521203490422964"},"user_tz":-480},"id":"Pt3igws3eiVp"},"outputs":[],"source":["os.chdir('pytorch-CycleGAN-and-pix2pix/')"]},{"cell_type":"code","execution_count":3,"metadata":{"metadata":{}},"outputs":[{"name":"stdout","output_type":"stream","text":["/home/blueee/AI-cup-2024-spring/pytorch-CycleGAN-and-pix2pix\n"]}],"source":["!pwd"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":270166,"status":"ok","timestamp":1710751377419,"user":{"displayName":"D Parejo","userId":"17109521203490422964"},"user_tz":-480},"id":"z1EySlOXwwoa","outputId":"c6e39497-644b-4194-8777-d69d971d726e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install -q -r requirements.txt"]},{"cell_type":"markdown","metadata":{},"source":["# Train 2 domain-specific models\n","- one for RIVER\n","- one for ROAD"]},{"cell_type":"markdown","metadata":{},"source":["## Datasets\n","\n","Put the dataset in the `pytorch-CycleGAN-and-pix2pix/datasets` folder\n","\n","(We have finished this part at the previous step when running `preprocess_dataset.ipynb`)\n","\n","Each dataset should have the following directory structure:\n","\n","```\n","datasets\n","└── train_ROAD\n","    ├── train\n","    ├── test\n","└── train_RIVER\n","    ├── train\n","    ├── test\n","```"]},{"cell_type":"markdown","metadata":{},"source":["## Training Arguments\n","Add argument:\n","- `--n_epochs=900 (default 100)`\n","- `--n_epochs_decay=100 (default 100)`\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# add the n_epochs and n_epochs_decay parameters up to total 400 epochs for each model\n","! python train.py --dataroot ./datasets/train_ROAD --name ROAD_pix2pix --model pix2pix --direction AtoB --n_epochs 900 --n_epochs_decay 100 --display_id 0\n","! python train.py --dataroot ./datasets/train_RIVER --name RIVER_pix2pix --model pix2pix --direction AtoB --n_epochs 900 --n_epochs_decay 100 --display_id 0\n","\n","# use nohup to run the training in the background\n","# ! nohup python train.py ... > road.log &\t\n","# ! nohup python train.py ... > river.log &"]},{"cell_type":"markdown","metadata":{},"source":["## Results\n","after training, you can find the results in \n","- `pytorch-CycleGAN-and-pix2pix/checkpoints/ROAD_pix2pix` folder\n","- `pytorch-CycleGAN-and-pix2pix/checkpoints/RIVER_pix2pix` folder\n","\n","Each folder contains:\n","- `/web/index.html` for the visualization of the results\n","- `latest_net_G.pth` for the latest model"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"environment":{"name":"tf2-gpu.2-3.m74","type":"gcloud","uri":"gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m74"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":0}
